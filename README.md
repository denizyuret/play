# research

TODO
* Implement RAM versions of basic image utils, bubble graph
* Use tanh(alpha*x) for soft binarization
* Use separate learnt masks for three-value -1,0,1 networks
* RNN - residual connections
* RNN - reversible units

* finish resnet implementation
* do multiheadattn layer for shadi
* test bwn on cifar, mini-imagenets etc with resnet
* figure out xnor
* try tanh idea, regularization idea etc
